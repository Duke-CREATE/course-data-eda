{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "W390nLBmZlId"
      },
      "source": [
        "# Semantic Search\n",
        "\n",
        "In this notebook we will use Pinecone for semantic search. To begin we must install the required prerequisite libraries:\n",
        "\n",
        "----\n",
        "\n",
        "pip install \"pinecone-client[grpc]==2.2.1\" datasets==2.12.0 sentence-transformers==2.2.2\n",
        "\n",
        "----"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "hrSfFiIC5roI"
      },
      "source": [
        "## Data Preprocessing"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "kujS_e8s55oJ"
      },
      "source": [
        "The dataset preparation process requires a few steps:\n",
        "\n",
        "1. Load dataset from our directory.\n",
        "\n",
        "2. The text content of the dataset is embedded into vectors.\n",
        "\n",
        "3. We reformat into a `(id, vector, metadata)` structure to be added to Pinecone.\n",
        "\n",
        "We will see how steps `1`, `2`, and `3` are done in this section, but we won't implement `2` and `3` across the whole dataset until we reach the *upsert loop* as we will iteratively perform these two steps.\n",
        "\n",
        "In either case, this can take some time. If you'd rather skip the data preparation step and get straight to upserts and testing the semantic search functionality, you should \n",
        "refer to the [**fast notebook**](https://github.com/pinecone-io/examples/blob/master/docs/semantic-search.ipynb)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataframe Shape: (43482, 21)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Course ID</th>\n",
              "      <th>Class Nbr</th>\n",
              "      <th>Subject</th>\n",
              "      <th>Catalog</th>\n",
              "      <th>Descr</th>\n",
              "      <th>PI Name</th>\n",
              "      <th>Course Long Descr</th>\n",
              "      <th>Section</th>\n",
              "      <th>Component</th>\n",
              "      <th>Mode</th>\n",
              "      <th>...</th>\n",
              "      <th>Mtg Start</th>\n",
              "      <th>Mtg End</th>\n",
              "      <th>Pat</th>\n",
              "      <th>Start Date</th>\n",
              "      <th>End Date</th>\n",
              "      <th>Descr 1</th>\n",
              "      <th>Attribute Formal Desc</th>\n",
              "      <th>Term Descr</th>\n",
              "      <th>Career</th>\n",
              "      <th>Location</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>19</td>\n",
              "      <td>8275</td>\n",
              "      <td>AMES</td>\n",
              "      <td>165S</td>\n",
              "      <td>THE WORLD OF JAPANESE POP CULT</td>\n",
              "      <td>Maude,Daryl J</td>\n",
              "      <td>An examination of modern Japanese culture thro...</td>\n",
              "      <td>01</td>\n",
              "      <td>SEM</td>\n",
              "      <td>In Person</td>\n",
              "      <td>...</td>\n",
              "      <td>11:45:00.000000AM</td>\n",
              "      <td>1:00:00.000000PM</td>\n",
              "      <td>TTH</td>\n",
              "      <td>8/28/23</td>\n",
              "      <td>12/8/23</td>\n",
              "      <td>Languages 207</td>\n",
              "      <td>(ALP) Arts, Literature &amp; Performance</td>\n",
              "      <td>2023 Fall Term</td>\n",
              "      <td>UGRD</td>\n",
              "      <td>DURHAM</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>19</td>\n",
              "      <td>8275</td>\n",
              "      <td>AMES</td>\n",
              "      <td>165S</td>\n",
              "      <td>THE WORLD OF JAPANESE POP CULT</td>\n",
              "      <td>Maude,Daryl J</td>\n",
              "      <td>An examination of modern Japanese culture thro...</td>\n",
              "      <td>01</td>\n",
              "      <td>SEM</td>\n",
              "      <td>In Person</td>\n",
              "      <td>...</td>\n",
              "      <td>11:45:00.000000AM</td>\n",
              "      <td>1:00:00.000000PM</td>\n",
              "      <td>TTH</td>\n",
              "      <td>8/28/23</td>\n",
              "      <td>12/8/23</td>\n",
              "      <td>Languages 207</td>\n",
              "      <td>(CCI) Cross Cultural Inquiry</td>\n",
              "      <td>2023 Fall Term</td>\n",
              "      <td>UGRD</td>\n",
              "      <td>DURHAM</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>19</td>\n",
              "      <td>8275</td>\n",
              "      <td>AMES</td>\n",
              "      <td>165S</td>\n",
              "      <td>THE WORLD OF JAPANESE POP CULT</td>\n",
              "      <td>Maude,Daryl J</td>\n",
              "      <td>An examination of modern Japanese culture thro...</td>\n",
              "      <td>01</td>\n",
              "      <td>SEM</td>\n",
              "      <td>In Person</td>\n",
              "      <td>...</td>\n",
              "      <td>11:45:00.000000AM</td>\n",
              "      <td>1:00:00.000000PM</td>\n",
              "      <td>TTH</td>\n",
              "      <td>8/28/23</td>\n",
              "      <td>12/8/23</td>\n",
              "      <td>Languages 207</td>\n",
              "      <td>(CZ) Civilizations</td>\n",
              "      <td>2023 Fall Term</td>\n",
              "      <td>UGRD</td>\n",
              "      <td>DURHAM</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>19</td>\n",
              "      <td>8275</td>\n",
              "      <td>AMES</td>\n",
              "      <td>165S</td>\n",
              "      <td>THE WORLD OF JAPANESE POP CULT</td>\n",
              "      <td>Maude,Daryl J</td>\n",
              "      <td>An examination of modern Japanese culture thro...</td>\n",
              "      <td>01</td>\n",
              "      <td>SEM</td>\n",
              "      <td>In Person</td>\n",
              "      <td>...</td>\n",
              "      <td>11:45:00.000000AM</td>\n",
              "      <td>1:00:00.000000PM</td>\n",
              "      <td>TTH</td>\n",
              "      <td>8/28/23</td>\n",
              "      <td>12/8/23</td>\n",
              "      <td>Languages 207</td>\n",
              "      <td>Crosslisted in another department</td>\n",
              "      <td>2023 Fall Term</td>\n",
              "      <td>UGRD</td>\n",
              "      <td>DURHAM</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>19</td>\n",
              "      <td>8275</td>\n",
              "      <td>AMES</td>\n",
              "      <td>165S</td>\n",
              "      <td>THE WORLD OF JAPANESE POP CULT</td>\n",
              "      <td>Maude,Daryl J</td>\n",
              "      <td>An examination of modern Japanese culture thro...</td>\n",
              "      <td>01</td>\n",
              "      <td>SEM</td>\n",
              "      <td>In Person</td>\n",
              "      <td>...</td>\n",
              "      <td>11:45:00.000000AM</td>\n",
              "      <td>1:00:00.000000PM</td>\n",
              "      <td>TTH</td>\n",
              "      <td>8/28/23</td>\n",
              "      <td>12/8/23</td>\n",
              "      <td>Languages 207</td>\n",
              "      <td>Seminar</td>\n",
              "      <td>2023 Fall Term</td>\n",
              "      <td>UGRD</td>\n",
              "      <td>DURHAM</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 21 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   Course ID  Class Nbr Subject Catalog                           Descr  \\\n",
              "0         19       8275    AMES    165S  THE WORLD OF JAPANESE POP CULT   \n",
              "1         19       8275    AMES    165S  THE WORLD OF JAPANESE POP CULT   \n",
              "2         19       8275    AMES    165S  THE WORLD OF JAPANESE POP CULT   \n",
              "3         19       8275    AMES    165S  THE WORLD OF JAPANESE POP CULT   \n",
              "4         19       8275    AMES    165S  THE WORLD OF JAPANESE POP CULT   \n",
              "\n",
              "         PI Name                                  Course Long Descr Section  \\\n",
              "0  Maude,Daryl J  An examination of modern Japanese culture thro...      01   \n",
              "1  Maude,Daryl J  An examination of modern Japanese culture thro...      01   \n",
              "2  Maude,Daryl J  An examination of modern Japanese culture thro...      01   \n",
              "3  Maude,Daryl J  An examination of modern Japanese culture thro...      01   \n",
              "4  Maude,Daryl J  An examination of modern Japanese culture thro...      01   \n",
              "\n",
              "  Component       Mode  ...          Mtg Start            Mtg End  Pat  \\\n",
              "0       SEM  In Person  ...  11:45:00.000000AM   1:00:00.000000PM  TTH   \n",
              "1       SEM  In Person  ...  11:45:00.000000AM   1:00:00.000000PM  TTH   \n",
              "2       SEM  In Person  ...  11:45:00.000000AM   1:00:00.000000PM  TTH   \n",
              "3       SEM  In Person  ...  11:45:00.000000AM   1:00:00.000000PM  TTH   \n",
              "4       SEM  In Person  ...  11:45:00.000000AM   1:00:00.000000PM  TTH   \n",
              "\n",
              "  Start Date End Date        Descr 1                 Attribute Formal Desc  \\\n",
              "0    8/28/23  12/8/23  Languages 207  (ALP) Arts, Literature & Performance   \n",
              "1    8/28/23  12/8/23  Languages 207          (CCI) Cross Cultural Inquiry   \n",
              "2    8/28/23  12/8/23  Languages 207                    (CZ) Civilizations   \n",
              "3    8/28/23  12/8/23  Languages 207     Crosslisted in another department   \n",
              "4    8/28/23  12/8/23  Languages 207                               Seminar   \n",
              "\n",
              "       Term Descr Career Location  \n",
              "0  2023 Fall Term   UGRD   DURHAM  \n",
              "1  2023 Fall Term   UGRD   DURHAM  \n",
              "2  2023 Fall Term   UGRD   DURHAM  \n",
              "3  2023 Fall Term   UGRD   DURHAM  \n",
              "4  2023 Fall Term   UGRD   DURHAM  \n",
              "\n",
              "[5 rows x 21 columns]"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# load course dataset\n",
        "dataset_df = pd.read_csv('data/all_minus_med.csv')\n",
        "print('Dataframe Shape:', dataset_df.shape)\n",
        "dataset_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The dataset contains 43482 courses and information about their description, subject, number, times offered, etc. at Duke University."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ngFHND1nQQU2"
      },
      "source": [
        "The dataset contains ~400K pairs of natural language questions from Quora."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "H_Zy8zoeQmRZ"
      },
      "source": [
        "We can extract all course descriptions into a single `descriptions` list."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "heGUpy_37Eis",
        "outputId": "a9b61af4-6595-44fc-bd35-7a7501b26123"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1 ) This course explores tropes, muses and icons of Black femininity in contemporary art. Graduate students enrolled in this seminar will consider diverse media, including photography, collage, craft and assemblage, as well as representations of the Black female body, of beauty and sexuality. In addition to reading canonic works in Black feminist theory, students will explore major works and exhibitions to consider the efforts of Black women art-makers from the 1960s through the 21st century.\n",
            "\n",
            "2 ) Introduction to film and television acting. Prerequisite: Theater Studies 145S Acting.\n",
            "\n",
            "3 ) Subjects of an interdepartmental nature in engineering tailored to the advanced undergraduate student or first- or second-year graduate student. Instructor consent is required.\n",
            "\n",
            "4 ) The intersection of healthcare and documentary photography. Explore work of established photographers engaged with healthcare topics. Produce semester-long documentary photography project and 5-10 page documentary essay on healthcare related topic. Students must have or quickly develop proficiency in the use of a digital SLR camera and Adobe Lightroom. Course materials include photographs, articles, and books. Class sessions combine critique of student work, discussion of course materials, and discussion of ethical questions involved in documentary representation of healthcare-related topics.\n",
            "\n",
            "5 ) Introduction to theories of criminal behavior from developmental and psychological perspectives, with focus on scientific and public perspectives. Investigate risk and protective factors influencing the development of delinquency and crime, systemic and sociocultural factors, ethical controversies, and applied topics in criminal behavior. Students critically evaluate, synthesize, and debate cases in context of current empirical research. Interactive learning emphasized. Open only to students in the Focus Program.\n",
            "\n",
            "Number of unique course descriptions: 3487\n"
          ]
        }
      ],
      "source": [
        "# convert course descriptions to list\n",
        "descriptions = dataset_df['Course Long Descr'].tolist()\n",
        "# remove duplicates\n",
        "descriptions = list(set(descriptions))\n",
        "\n",
        "# print first 5 descriptions\n",
        "for i in range(5):\n",
        "    print(i+1, ')', descriptions[i])\n",
        "    print()\n",
        "\n",
        "# print number of descriptions\n",
        "print('Number of unique course descriptions:', len(descriptions))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We find the mean, median, minimum, and maximumm number of words in descriptions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Minimum number of words: 2\n",
            "Maximum number of words: 262\n",
            "Median number of words: 61\n",
            "Mean number of words: 60.75444635685599\n"
          ]
        }
      ],
      "source": [
        "# Calculate the number of words for each description\n",
        "num_words = [len(description.split()) for description in descriptions if isinstance(description, str)]\n",
        "\n",
        "# Calculate the minimum, maximum, median, and mean number of words\n",
        "minimum = min(num_words)\n",
        "maximum = max(num_words)\n",
        "median = sorted(num_words)[len(num_words) // 2]\n",
        "mean = sum(num_words) / len(num_words)\n",
        "\n",
        "# Print the results\n",
        "print(\"Minimum number of words:\", minimum)\n",
        "print(\"Maximum number of words:\", maximum)\n",
        "print(\"Median number of words:\", median)\n",
        "print(\"Mean number of words:\", mean)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "4BknpfucRkkm"
      },
      "source": [
        "With our descriptions ready to go we can move on to demoing steps **2** and **3** above.\n",
        "\n",
        "### Building Embeddings and Upsert Format\n",
        "\n",
        "To create our embeddings we will us the `MiniLM-L6` sentence transformer model. This is a very efficient semantic similarity embedding model from the `sentence-transformers` library. We initialize it like so:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uxcGjb9GSEqA",
        "outputId": "e3b269d0-c7f4-41d8-85ad-5a94a0b79d8d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You are using cpu. This is much slower than using a CUDA-enabled GPU. If on Colab you can change this by clicking Runtime > Change runtime type > GPU.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "SentenceTransformer(\n",
              "  (0): Transformer({'max_seq_length': 256, 'do_lower_case': False}) with Transformer model: BertModel \n",
              "  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False})\n",
              "  (2): Normalize()\n",
              ")"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "import torch\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "if device != 'cuda':\n",
        "    print(f\"You are using {device}. This is much slower than using \"\n",
        "          \"a CUDA-enabled GPU. If on Colab you can change this by \"\n",
        "          \"clicking Runtime > Change runtime type > GPU.\")\n",
        "\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2', device=device)\n",
        "model"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "iy2itPb0S5js"
      },
      "source": [
        "There are *three* interesting bits of information in the above model printout. Those are:\n",
        "\n",
        "* `max_seq_length` is `256`. That means that the maximum number of tokens (like words) that can be encoded into a single vector embedding is `256`. Anything beyond this *must* be truncated.\n",
        "\n",
        "* `word_embedding_dimension` is `384`. This number is the dimensionality of vectors output by this model. It is important that we know this number later when initializing our Pinecone vector index.\n",
        "\n",
        "* `Normalize()`. This final normalization step indicates that all vectors produced by the model are normalized. That means that models that we would typical measure similarity for using *cosine similarity* can also make use of the *dotproduct* similarity metric. In fact, with normalized vectors *cosine* and *dotproduct* are equivalent.\n",
        "\n",
        "Moving on, we can create a sentence embedding using this model like so:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dyzoJEsAULOe",
        "outputId": "a1ea6149-4b2d-4dfb-e984-b067fb9980d5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(384,)"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "query = 'classes that teach about machine learning'\n",
        "\n",
        "xq = model.encode(query)\n",
        "xq.shape"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "qVZi8xevUWM6"
      },
      "source": [
        "Encoding this single sentence leaves us with a `384` dimensional sentence embedding (aligned to the `word_embedding_dimension` above).\n",
        "\n",
        "To prepare this for `upsert` to Pinecone, all we do is this:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "T38HdqxwVg6p"
      },
      "outputs": [],
      "source": [
        "_id = '0'\n",
        "metadata = {'text': query}\n",
        "\n",
        "vectors = [(_id, xq, metadata)]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "wiXig_rHV2Wz"
      },
      "source": [
        "Later when we do upsert our data to Pinecone, we will be doing so in batches. Meaning `vectors` will be a list of `(id, embedding, metadata)` tuples."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ebd7XSamfMsC"
      },
      "source": [
        "## Creating an Index\n",
        "\n",
        "Now the data is ready, we can set up our index to store it.\n",
        "\n",
        "We begin by initializing our connection to Pinecone. To do this we need a [free API key](https://app.pinecone.io)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "mc66NEBAcQHY"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pinecone\n",
        "\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "# get api key from app.pinecone.io\n",
        "api_key = os.environ.get('PINECONE_API_KEY')\n",
        "# find your environment next to the api key in pinecone console\n",
        "env = os.environ.get('PINECONE_ENVIRONMENT', 'env')\n",
        "\n",
        "pinecone.init(\n",
        "    api_key=api_key,\n",
        "    environment='gcp-starter'\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "SdaTip6CfllN"
      },
      "source": [
        "Now we create a new index called `duke-course-desc`. It's important that we align the index `dimension` and `metric` parameters with those required by the `MiniLM-L6` model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "tags": [
          "parameters"
        ]
      },
      "outputs": [],
      "source": [
        "index_name = 'duke-course-desc'\n",
        "hostname='https://duke-course-desc-ea5f15c.svc.gcp-starter.pinecone.io'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "p1pyQh8gfm2-"
      },
      "outputs": [],
      "source": [
        "# only create index if it doesn't exist\n",
        "if index_name not in pinecone.list_indexes():\n",
        "    pinecone.create_index(\n",
        "        name=index_name,\n",
        "        dimension=model.get_sentence_embedding_dimension(),\n",
        "        metric='cosine',\n",
        "        hostname=hostname\n",
        "    )\n",
        "# now connect to the index\n",
        "index = pinecone.Index(index_name)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "YUd1VGg6i108"
      },
      "source": [
        "Now we upsert the data, we will do this in batches of `128`.\n",
        "\n",
        "_**Note:** On Google Colab with GPU expected runtime is ~7 minutes. If using CPU this will be significantly longer. If you'd like to get this running faster refer to the [fast notebook](https://github.com/pinecone-io/examples/blob/master/search/semantic-search/semantic-search-fast.ipynb)._"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120,
          "referenced_widgets": [
            "0e5dc9a271184100a92cd6b373ab8e7d",
            "8396bfd36c2b4869a0b4680587b604f1",
            "d714f8b3ebca4195b747ab18d196b88b",
            "56266bc7062541f5ba042848205270ef",
            "78fab28034dd428c9f49a5653fd003e5",
            "d8ca1c42783f41a8bd17491073883fdd",
            "cffd5e66b82344b0946630eb320ca5b4",
            "b63c0eee680f4708a4c68a4746cb21a4",
            "12e8c994f3ac4f88ae5387c72b4d8cc7",
            "9ea70e9ea5fb4040a080b941950b0fef",
            "b30a98ddfc1841e381937571edcfae71"
          ]
        },
        "id": "RhR6WOi1huXZ",
        "outputId": "ef9f74ef-2ae3-4eb3-cef4-6814e98861a7"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0e5dc9a271184100a92cd6b373ab8e7d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1063 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "{'dimension': 384,\n",
              " 'index_fullness': 0.1,\n",
              " 'namespaces': {'': {'vector_count': 136057}},\n",
              " 'total_vector_count': 136057}"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from tqdm.auto import tqdm\n",
        "\n",
        "batch_size = 128\n",
        "vector_limit = 100000\n",
        "\n",
        "descriptions = descriptions[:vector_limit]\n",
        "\n",
        "for i in tqdm(range(0, len(descriptions), batch_size)):\n",
        "    # find end of batch\n",
        "    i_end = min(i+batch_size, len(descriptions))\n",
        "    # create IDs batch\n",
        "    ids = [str(x) for x in range(i, i_end)]\n",
        "    # create metadata batch\n",
        "    metadatas = [{'text': text} for text in descriptions[i:i_end]]\n",
        "    # create embeddings\n",
        "    xc = model.encode(descriptions[i:i_end])\n",
        "    # create records list for upsert\n",
        "    records = zip(ids, xc, metadatas)\n",
        "    # upsert to Pinecone\n",
        "    index.upsert(vectors=records)\n",
        "\n",
        "# check number of records in the index\n",
        "index.describe_index_stats()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "VrK_IN079Vuu"
      },
      "source": [
        "## Making Queries"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "rr4unPAq9alb"
      },
      "source": [
        "Now that our index is populated we can begin making queries. We are performing a semantic search for *similar questions*, so we should embed and search with another question. Let's begin."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JWcO7jAK-N_1",
        "outputId": "db437488-c928-4fd7-e4b7-83c93ac67f88"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'matches': [{'id': '31072',\n",
              "              'metadata': {'text': 'What country has the biggest population?'},\n",
              "              'score': 0.7655585,\n",
              "              'sparse_values': {'indices': [], 'values': []},\n",
              "              'values': []},\n",
              "             {'id': '23769',\n",
              "              'metadata': {'text': 'What is the biggest city?'},\n",
              "              'score': 0.7271395,\n",
              "              'sparse_values': {'indices': [], 'values': []},\n",
              "              'values': []},\n",
              "             {'id': '65783',\n",
              "              'metadata': {'text': 'What is the most isolated city in the '\n",
              "                                   'world, with over a million metro area '\n",
              "                                   'inhabitants?'},\n",
              "              'score': 0.7020447,\n",
              "              'sparse_values': {'indices': [], 'values': []},\n",
              "              'values': []},\n",
              "             {'id': '104484',\n",
              "              'metadata': {'text': 'Which is the most beautiful city in '\n",
              "                                   'world?'},\n",
              "              'score': 0.69991666,\n",
              "              'sparse_values': {'indices': [], 'values': []},\n",
              "              'values': []},\n",
              "             {'id': '79997',\n",
              "              'metadata': {'text': 'Where is the most beautiful city in the '\n",
              "                                   'world?'},\n",
              "              'score': 0.69605494,\n",
              "              'sparse_values': {'indices': [], 'values': []},\n",
              "              'values': []}],\n",
              " 'namespace': ''}"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "query = \"which city has the highest population in the world?\"\n",
        "\n",
        "# create the query vector\n",
        "xq = model.encode(query).tolist()\n",
        "\n",
        "# now query\n",
        "xc = index.query(xq, top_k=5, include_metadata=True)\n",
        "xc"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "-XwOWcgo_QtI"
      },
      "source": [
        "In the returned response `xc` we can see the most relevant questions to our particular query. We can reformat this response to be a little easier to read:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gy7isg_f-vWg",
        "outputId": "bbeee182-8e31-4bba-da39-38521b13683f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.77: What country has the biggest population?\n",
            "0.73: What is the biggest city?\n",
            "0.7: What is the most isolated city in the world, with over a million metro area inhabitants?\n",
            "0.7: Which is the most beautiful city in world?\n",
            "0.7: Where is the most beautiful city in the world?\n"
          ]
        }
      ],
      "source": [
        "for result in xc['matches']:\n",
        "    print(f\"{round(result['score'], 2)}: {result['metadata']['text']}\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "1JK5yApl_5fE"
      },
      "source": [
        "These are good results, let's try and modify the words being used to see if we still surface similar results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dJbjE-iq_yMr",
        "outputId": "b81c67b1-9fe7-48c3-d2b0-14100cbbc25d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.67: What is the most isolated city in the world, with over a million metro area inhabitants?\n",
            "0.64: What is the biggest city?\n",
            "0.61: Which place has the highest Asian Indian population in the USA?\n",
            "0.6: What is the most dangerous city in USA?\n",
            "0.59: What country has the biggest population?\n"
          ]
        }
      ],
      "source": [
        "query = \"which metropolis has the highest number of people?\"\n",
        "\n",
        "# create the query vector\n",
        "xq = model.encode(query).tolist()\n",
        "\n",
        "# now query\n",
        "xc = index.query(xq, top_k=5, include_metadata=True)\n",
        "for result in xc['matches']:\n",
        "    print(f\"{round(result['score'], 2)}: {result['metadata']['text']}\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "HIAxOPb-A2w_"
      },
      "source": [
        "Here we used different terms in our query than that of the returned documents. We substituted **\"city\"** for **\"metropolis\"** and **\"populated\"** for **\"number of people\"**.\n",
        "\n",
        "Despite these very different terms and *lack* of term overlap between query and returned documents â€” we get highly relevant results â€” this is the power of *semantic search*.\n",
        "\n",
        "You can go ahead and ask more questions above. When you're done, delete the index to save resources:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "-cWdeKzhAtww"
      },
      "outputs": [],
      "source": [
        "pinecone.delete_index(index_name)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "PMMJSu_DbRx0"
      },
      "source": [
        "---"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0e5dc9a271184100a92cd6b373ab8e7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8396bfd36c2b4869a0b4680587b604f1",
              "IPY_MODEL_d714f8b3ebca4195b747ab18d196b88b",
              "IPY_MODEL_56266bc7062541f5ba042848205270ef"
            ],
            "layout": "IPY_MODEL_78fab28034dd428c9f49a5653fd003e5"
          }
        },
        "12e8c994f3ac4f88ae5387c72b4d8cc7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "56266bc7062541f5ba042848205270ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9ea70e9ea5fb4040a080b941950b0fef",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_b30a98ddfc1841e381937571edcfae71",
            "value": " 1063/1063 [02:48&lt;00:00,  6.41it/s]"
          }
        },
        "78fab28034dd428c9f49a5653fd003e5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8396bfd36c2b4869a0b4680587b604f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d8ca1c42783f41a8bd17491073883fdd",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_cffd5e66b82344b0946630eb320ca5b4",
            "value": "100%"
          }
        },
        "9ea70e9ea5fb4040a080b941950b0fef": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b30a98ddfc1841e381937571edcfae71": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b63c0eee680f4708a4c68a4746cb21a4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cffd5e66b82344b0946630eb320ca5b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d714f8b3ebca4195b747ab18d196b88b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b63c0eee680f4708a4c68a4746cb21a4",
            "max": 1063,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_12e8c994f3ac4f88ae5387c72b4d8cc7",
            "value": 1063
          }
        },
        "d8ca1c42783f41a8bd17491073883fdd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
